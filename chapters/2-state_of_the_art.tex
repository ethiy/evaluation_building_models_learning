\minitoc

\vfill

\clearpage

\section{Automatic building \gls*{acr::3d} modelling}
    \label{sec::state_of_the_art::building_modeling}

    \subsection{Input data classification}
        \label{subsec::state_of_the_art::building_modeling::input}

    \subsection{Strategy classification}
        \label{subsec::state_of_the_art::building_modeling::strategy}

    \subsection{Scale classification}
        \label{subsec::state_of_the_art::building_modeling::scale}

\section{Quality evaluation of \gls*{acr::3d} building models}
    \label{sec::state_of_the_art::quality}
    We have seen previously the various methods used to automatically model building.
    The goal of this section is to describe the available approaches that evaluate the quality of such models.
    These could be distinguished based on two criteria.
    In subsection~\ref{subsec::state_of_the_art::quality::output}, are presented the quality evaluation methods based on their output.
    An alternative prespective to charecterize quality evaluation methods: it relies upon the type of reference data (\textit{cf.} subsection~\ref{subsec::state_of_the_art::quality::reference}).

    \subsection{Output types}
        \label{subsec::state_of_the_art::quality::output}
        We distinguish herein quality evaluation methods based on the output they produce.
        Fidelity metrics is a first instance of output types.
        The second is semantic labels.
        In what follows, we explain, in details, the differences between the two method types.

        \subsubsection{Fidelity metrics based methods}
            One way to charecterize the quality of a building model is to compute indices or metrics reporting its accuracy.\\

            Most metrics provide information on the geometric precision of the model.
            These are computed at different levels.
            They are categorized here depending on the geometric dimension of the objects in question.\\
            We start with zero dimensional objects: \textit{i.e.} points.
            In this case, metrics are based on their coordinates.
            The goal is to detect positional inaccuraccies~\parencite{kaartinen2005accuracy}.
            In constrast, the choice of points to be inspected is not simple.
            Corner points resulting from the intersection of edges in the model is one choice.
            In fact,~\textcite{zeng2014multicriteria} registers corner points from the evaluated model and the corresponding reference.
            Based on this registration, a comparison is drawn using \gls{acr::rmse}, just as in~\parencite{landes2012quality} and~\parencite{you2011quality}.
            The same points are used as a proxy for manual quality inspection by~\textcite{elberink2011quality}.
            Another alternative is to sample points from lines or surfaces to be compared.
            These could be predetermined manually as in~\textcite{kaartinen2005accuracy} or sampled regularely as demonstrated by~\textcite{vogtle2003quality} or by~\textcite{tran2019geometric}.
            Imprecisions are not computed only relying the \gls{acr::rmse}, but can also be separated into planimetric and height inaccuraccies~\parencite{vogtle2003quality, kaartinen2005accuracy, jaynes2003recognition}.\\
            Second comes edges and all one dimensional objects in general.
            These convey structural, in addition to positional, informations.
            \textcite{kaartinen2005accuracy} compares lengths as well as slopes of edges formed by reference points.
            Edges metrics are also used as a intermediary as shown by~\textcite{elberink2011quality} and~\textcite{michelin2013quality}.
            They are both interested in intersection edges.
            While the first relies on \gls{acr::rmse}, the second computes more complex metrics that compares model edges to ones that are extracted based on sensor data.\\
            Next, at the second dimension, are compared surfaces, bounded (for example, polygons) or not (like planes).
            These hold more topological information than the first ones and hence are widely used for evaluation.
            \textcite{rottensteiner2014results} used height discrepency of roof planes so as to evaluate building models.
            This ideal for Manhattan-world assumptions as was the case of~\textcite{zebedin2008fusion}.
            In addition to height discrepency, normal displacement is computed using always the same metric by~\textcite{henricsson19973}.
            Conversely,~\textcite{zeng2014multicriteria} uses also a \gls{acr::rmse} for comparison, but not in the Euclidean space.
            In fact, after mapping the evaluated and reference models to a sphere, they compare their spherical harmonic~\parencite{brechbuhler1995parametrization} representations.
            Just as with edges, planes can be evaluated using angular measurements, as was proposed by~\textcite{landes2012quality} and~\textcite{henricsson19973}.
            Another alternative is to compare reconstructed and reference models based on surface area comparisons.
            These are mostly based on ratios like completeness and correctness\footnote{in other words, recall and precision respectively.}~\parencite{rottensteiner2014results,landes2012quality,henricsson19973,schuster2003new}.\\
            Last, are three dimensional (\textit{i.e.} volume) evaluation.
            The same detection ratios that were computed for surfaces are again calculated to evaluate volumes this times, as shown by~\textcite{mohamed2013quality, zeng2014multicriteria,jaynes2003recognition,nguatem2017modeling}.
            These are the only metrics used for volumes that we are aware of.\\

            Regarding \textit{implicit} semantics, as far as we are aware, only one metric is widely used to evaluate its impact.
            As discussed previously in subsection~\ref{subsec::introduction::urban_3d_reconstruction::building_3d_modeling}, compaction is one byproduct of semantics.
            As a consequence, it was used as a index to evaluate reconstructions\footnote{It is sometimes called by its antonym: complexity.}: the more a model was compact the better it was.
            This is reflected, for instance, in the work of~\textcite{lafarge_ijcv12},~\textcite{zhang2017deep},~\textcite{duan_eccv16},~\textcite{zeng2018neural} and~\textcite{zhu2018large}.

        \subsubsection{Semantic labels based methods}
            In a drive to provide a quantitative assessment of building models, the previously defined metrics fail to convey specific and localized information about a predetermined building model.
            These indices are usually used to give a general idea of the quality of models produced by some modeling method.
            Moreover, they do not usually carry semantics, which is critical for further processing steps such as manual correction~\parencite{elberink2011quality}.
            Some evaluation methods, in an effort to alleviate these issues, yield semantic labels that describe the errors of an evaluated model.
            Hereafter, are described the different types of labels that were proposed in the literature.\\

            The first ever work, that we are aware of, which tackles proposes semantic labels as outputs of the evaluation is by~\textcite{boudet2006supervised}.
            The approach presented by the latter has four classes which indicate how much valid can the modeling be: ``acceptable'' and ``correct'' portray valid buildings while ``false"``and ``generalized"``are refused.
            It can be seen as a four grade based score system expressing the confidence in a building model.
            The main limitation of this method is the fact that the proposed labels do not specify what defects does models present if it is not valid.
            It is, therefore, hard to use for model correction.
            The confidence scoring depends also on each use case.
            For instance, a comunications company would be more adament on the accuracy of roof parts, which would affect wave propagation, rather than a insurance company interested in flood damage estimation.
            This means that each use case implies a relabeling that could be potentially different from other one.\\
            The first hints of a fine grained semantic labeling of building model errors lay in the work of~\textcite{rottensteiner2014results}.
            They are the first to report segmentation issues in labels instead of a global ratio.
            They distinguish between oversegmentation cases, undersegmentation cases and cases where both co-occur.\\
            These mentioned errors are not comprehensive: they do not cover all possible building model errors.
            \textcite{michelin2013quality} came up with a rich taxonomy of errors that are categorized into three big families:
            \begin{itemize}
                \item Footprint errors: these portray errors relative to the building footprint, which is used by many modeling algorithms as input.
                        Errors contained in this family are: ``erroneous outline'', ``unexisting building'', ``missing inner court'' and ``inaccurate footprint''.
                \item Reconstruction errors: these are caused by the modeling approach.
                        These defects can be the result of the incompatibility of some \textit{a priori} hypotheses about the scene, for instance.
                        Such errors are: ``under-segmentation'', ``over-segmentation'', ``inaccurate roof'' and ``Z translation''.
                \item Vegetation errors: this corresponds to a special case when modeled building are occluded, completely or partially, by vegetation.
                        It becomes impossible to evaluate properly these models.
            \end{itemize}
            Although the last taxonomy being rich, it is not exhaustive enough as it misses cases that are not present in the urban zone that was studied in the paper, such as inaccurate primitive fitting.
            Moreover, it adopts the point of view of the modeling method that was used to provide their dataset.
            Knowing the specific weaknesses of the latter guided the choice of error family classification and the error definitions.

    \subsection{Reference data types}
        \label{subsec::state_of_the_art::quality::reference}
        In order to evaluate models, reference data are utilized for comparison.
        Based on the latter, another way to discriminate among modeling methods is possible.
        The first class of reference data are high quality ground truth building \gls{acr::3d} models.
        Remote sensing data is the second alternative that is used for reference.
        Hereafter, is explained the difference between the two categories.

        \subsubsection{High resolution ground truth}
            Ground truth building models are mainly acquired manually.
            Herein, are listed the different ground truth measurement techniques, in descending order of accuracy.\\

            The most obvious case consists in field measurements of the modeled building.
            \textcite{dick2004modelling}, for instance, evaluated their buildings based on manual measurements taken on specific architectural features, like windows and columns, with an accuracy of \SI{0.01}{\m} for the first and \SI{0.1}{\m} for the second.
            Complete and scalables measurements of buildings are possible using topographic survey.
            Using the latter, building models could be reconstructed with precision up to \SI{\pm 0.1}{\m}~\parencite{henricsson19973} or \SI{\pm 0.05}{\m}~\parencite{vogtle2003quality}.\\
            There is also the possibility of manually modeling the building using oblique images, or stereoplotting.
            ~\textcite{zebedin2008fusion} uses such a method to produce their reference data from aerial images with accuracy up to the order of \SI{\pm 0.15}{\m}.
            The same procedure was used also by~\textcite{jaynes2003recognition} producing models with inaccuraccies bounded by \SI{\pm 1/3}{\m}.

        \subsubsection{Remote sensing data}
            Reference ground truth models are not easy to come by~\parencite{schuster2003new}.
            The previous choice is hard to scale up to district or city levels.
            On the other hand, remote sensing data, which are more available, could be used, instead, as reference.
            In fact, since these are usually fed as input in modeling methods, it is only reasonable to evaluate the produced models in comparison to the intake.
            Listed here, are the different types of remote sensing data and how they could be used for building model evaluation.\\

            Aerial images are the first example of reference data used in building model evaluation.
            These could be original oblique images or preprocessed orthoimages.
            The first class of images are the most precise but the other one is more available.
            Oblique images were used by~\textcite{michelin2013quality} to extract \gls{acr::3d} segments based on plane sweeping techniques.
            Reference edges are filtered out and are used to evaluate the \gls{acr::3d} model (intersection) edges.
            Based on these segments,~\textcite{boudet2006supervised} not only evaluates edges but also corners (\textit{i.e.} edge intersections) and planes.
            Facet were also evaluated, in~\parencite{boudet2006supervised}, based on correlation functions computed from multiple overlapping oblique images.
            Orthoimages were used also to, for instance, compute \gls{acr::ndvi} scores for vegetation occluded building model discrimination.\\
            Second, are \gls{acr::lidar} point clouds.
            This type of data have the inherent advantage, compared to images, of natively providing depth information.
            \textcite{kaartinen2005accuracy} used data that was acquired multiple times with a guarantied precision up to \SI{0.083}{\cm} in plane and \SI{0.035}{\cm} in height.
            Out of the latter were chosen reference points that were compared to equivalents in the evaluated building models (check the previous subsubsection).
            All the points could also be used for comparison by computing metrics such as \gls{acr::rmse}~\parencite{lafarge_ijcv12,zhu2018large}.
            Original input data is not always accessible.
            One issue arises when using different data: data registration.
            This is taken into account by~\textcite{akca2010quality}, before addressing the completeness of building models.\\
            Third and last, are presented height maps.
            These are not sensor data as they are a byproduct of earlier data types.
            Still, they are considered here since they are used as input by some building modeling pipelines.
            Just like with \gls{acr::lidar}, \gls{acr::dsm} is used for building models comparison based on \gls{acr::rmse}~\parencite{zeng2018neural}.
            \textcite{michelin2013quality}, however, uses the same data but differently.
            In fact, \gls{acr::dsm}, being a result of oblique images, can be used as proxy, to help extracting \gls{acr::3d} geometric features instead of recomputing correlation scores like in~\parencite{boudet2006supervised}.
            It can also be valuable for missing court detection by calculating sky viewshed angle scores~\parencite{michelin2013quality}.

    \subsection{Objective statement}
\section{Supervised learning and pattern recognition}
    \subsection{Classifiers}
        \subsubsection{Perceptron}
            In an effort to understand neural activity,~\textcite{rosenblatt1958perceptron} proposed the perceptron model.
            This is the first building block in \gls{acr::nn}.
            It has as input a number $d$ of stimuli, each one denoted $x_i,\quad \forall i = 1,2,\dots,d$.
            For each stimulus indexed by $i\in \{1,\dots,d\}$, is associated a weight $w_i$.
            Written in vectorial form, $\bm{x} = \begin{pmatrix}x_1\\ x_2\\ \vdots \\ x_d \end{pmatrix}$ (\textit{resp.} $\bm{w} = \begin{pmatrix}w_1\\ w_2\\ \vdots \\w_d \end{pmatrix}$) represent the input (\textit{resp.} the weights).
            A score is obtained from a linear combination of all the stimuli: $s = \bm{w} \cdot \bm{x} = \sum_{i=1}^{d} w_i \cdot x_i$.
            If the score is above a certain threshold $\theta \in \mathbb{R}$, the output of the perceptron is $1$.
            Otherwise, the result is $0$.
            The result of a perceptron can be summarized as:
            \begin{equation}
                \label{eq::perceptron}
                \mathbf{D}_{perceptron}(\bm{x}) \triangleq \mathbb{1}_{\bm{w} \cdot \bm{x} \geq \theta} \quad.
            \end{equation}
            It could be rewritten also as:
            \begin{equation}
                \label{eq::perceptron_is_linear}
                \mathbf{D}_{perceptron}(\bm{x}) \triangleq \mathbb{1}_{\bm{w} \cdot \bm{x} + b \geq 0}
            \end{equation}
            where:
            \begin{conditions}
                b & is called bias and $b = - \theta $.
            \end{conditions}
            We recognize here the decision function of a linear binary classifier.
            This classifier model is not used widely, but as mentioned earlier, is a essential ingredient of \glspl{acr::nn}.
            It combines a linear operation $\bm{x} \mapsto \bm{w} \cdot \bm{x} + b$ and a non linear one $a: s \mapsto \mathbb{1}_{s \geq 0}$.
            The latter is an example of what is called an activation function.
            The choice of the latter plays a critical role in the learning capability of the classifier.
        \subsubsection{\acrlong*{acr::svm}}
            \glspl{acr::svm} are a special type of linear classifiers (\textit{i.e.} perceptrons).
            We transfrom the initial classes $\big(y^k\big)_{k=1,\dots,n}$ to $\big(\tilde{y}^k\big)_{k=1,\dots,n}$, using the map: $y \mapsto \tilde{y} = 2\cdot y - 1$.
            There are always two possible classes $\{1, -1\}$.
            This simple transformation is done to simplify the later equations.
            In order to understand the idea behind the \gls{acr::svm} classifier, we start by assuming that the dataset to be classified $\big((\bm{x}^k, y^k)\big)_{k=1,\dots,n}$ is linearly separable.
            It means that there is at least one hyperplane $(H_0)$ that can separate perfectly the two classes.
            We can order points from one class based on their distance to the hyperplane $(H_0)$.
            As a reminder, in a metric space $(X, d)$, the distance of a point $x \in X$ to a subset $A \subset X$:
            \begin{equation}
                d(x, A) \triangleq \inf\{d(x, a): a \in A\}
            \end{equation}
            The closest positive (\textit{resp.} negative) points (\textit{i.e.} of class $1$ (\textit{resp.}  $-1$)) to $(H_0)$ is called positive (\textit{resp.} negative) support vectors and are denoted by $\bm{x}^+$ (\textit{resp.} $\bm{x}^-$).
            Support hyperplanes are the lines parallel to the separator and passing throough the support vectors.
            This can be summarized as:
            \begin{eqnarray}
                \{\bm{x}^+_s: s = 1, \dots, n_{psp}\} &\triangleq \arg\min\{d(\bm{x}_k, H_0) : k=1,\dots,n \wedge \tilde{y}^k = 1\}\\
                \{\bm{x}^-_s: s = 1, \dots, n_{nsp}\} &\triangleq \arg\min\{d(\bm{x}_k, H_0) : k=1,\dots,n \wedge \tilde{y}^k = -1\}
            \end{eqnarray}
            where:
            \begin{conditions}
                n_{psp} & is the number of positive support vectors.\\
                n_{nsp} & is the number of negative support vectors.\\
            \end{conditions}

            \begin{figure}
				\includestandalone[mode=buildnew, width=\textwidth]{figures/svm/linear_separable}
				\caption{
                    \label{fig::linear_separable} A linear separator in $\mathbb{R}^2$ corresponds to a line.
                    In this case, $n_{psp} = n_{nsp} = 1$.
                    As a consequence we did not index the support vectors.
                    $M$ is the margin.
                }
            \end{figure}

            In figure~\ref{fig::linear_separable}, we illustrate these notions.
            The more points are close to the separator, the more uncertain they are.
            Hence, support vectors being the last points which class is certain (since it is given), the points that lay between the two orange lines are the most uncertain ones.
            The bigger the distance between these two lines the more nuanced the classifier decision is.
            As a consequence, this distance has to be the biggest possible.
            This is the principle behind \glspl{acr::svm}.
            The optimized distance is called margin and denoted $M$.
            We write:
            \begin{equation*}
                Sol \triangleq \{\omega \in \mathbb{R}^d : \omega.\bm{x} + b = 0\}.
            \end{equation*}
            We verify that:
            \begin{equation*}
                \forall \lambda \in \mathbb{R}\setminus\{0\} \quad (\bm{w}, b) \in  Sol \Rightarrow (\lambda . \bm{w}, \lambda.b) \in Sol.
            \end{equation*}
            $(\bm{w}, b)$ is then chosen so that the support hyperplanes verify:
            \begin{equation}
                \label{eq::support_lines}
                \bm{w}\cdot\bm{x}^{\pm} + b = \pm 1
            \end{equation}
            The margin $M$ can be seen as the length of the orthogonal projection of a vector $\bm{v}$ going from a negative support vector to a positive one on any line carried by $\bm{w}$.
            The choice of the vector supports is not important when using such a projection.
            Consequently, we write $v = (\bm{x}^+ - \bm{x}^-)$.
            \begin{align*}
                M &= \frac{\bm{w}}{\Vert\bm{w}\Vert} \cdot (\bm{x}^+ - \bm{x}^-)\\
                  &= \frac{\bm{w}\cdot\bm{x}^+ - \bm{w}\cdot\bm{x}^-}{\Vert\bm{w}\Vert}\\
                  &= \frac{(\bm{w}\cdot\bm{x}^+ + b) - (\bm{w}\cdot\bm{x}^- + b)}{\Vert\bm{w}\Vert}\\
                  &= \frac{2}{\Vert\bm{w}\Vert}
            \end{align*}

            The \gls{acr::svm} problem is written as:
            \begin{equation*}
                \begin{aligned}
					& \max_{\bm{w}}
					& & M \\
					& \text{s.t.}
					& & \begin{cases}
						\bm{w}.\bm{x}^i + b \leq -1 & \tilde{y}^i = -1 \\
						\bm{w}.\bm{x}^i + b \geq 1 & \tilde{y}^i = 1
					\end{cases} \; \forall i = 1, \dots, n.
				\end{aligned}
            \end{equation*}
            Or:
            \begin{equation}
                \label{eq::separable_svm_primal}
                \begin{aligned}
					& \min_{\bm{w}}
					& & {\vert\vert \bm{w} \vert\vert}^2 \\
					& \text{s.t.}
					& & \tilde{y}^i.(\bm{w}.\bm{x}^i + b) \geq 1 \; \forall i = 1, \dots, n.
				\end{aligned}
            \end{equation}

            \paragraph{Linear \acrshort*{acr::svm}}
            \paragraph{Kernel \acrshort*{acr::svm}}
                \subparagraph{Usual kernels}
                \subparagraph{MKL}
            \paragraph{Properties}
        \subsubsection{Random Forest}
            \paragraph{Decision trees}
            \paragraph{Bagging decision trees}
            \paragraph{Properties}
    \subsection{Computer vision}
        \subsection{Edges and corners}
        \subsubsection{Scattering}
        \subsubsection{Convolutional neural networks}
    \subsection{Graph classification}
        \subsubsection{Graph kernels}
        \subsubsection{Graph neural networks}
