\minitoc

\vfill

In this Chapter, a tour of the different notions necessary for the understanding of the present manuscript is presented.
It is divided into three sections.
First, we categorize, in Section~\ref{sec::state_of_the_art::building_modeling}, the \gls{acr::3d} building modeling techniques.
A global idea of the subject is required to have a good idea of which defects to expect in evaluated building models.
Secondly, we present a complete state-of-the-art survey on quality evaluation for \gls{acr::3d} building models (cf. Section~\ref{sec::state_of_the_art::quality}).
In the last Section~\ref{sec::state_of_the_art::mlpr}, are presented the main tools that are used in our proposed approach.
Indeed, we discuss aspects of supervised classification as well as main feature extraction techniques.

\clearpage

\section{Automatic \texorpdfstring{\gls*{acr::3d}}{3D} building modeling}
    \label{sec::state_of_the_art::building_modeling}
    In this work, we study the quality evaluation of \textbf{large-scale} urban modeling.
    Building models at city scale cannot be obtained manually.
    Automatically acquired building models are, actually, the first target of our study.
    As a consequence, there is a need for a overview of automatic \gls{acr::3d} building modeling.
    The aim of this section is not to give a thorough survey of all \gls{acr::3d} modeling techniques, but rather explain the main approaches and how they affect the quality of the final product.
    For a comprehensive study of urban reconstruction methods, we refer the reader to the work of~\textcite{musialski2013survey}.\\

    Automatic \gls{acr::3d} building modeling consists mainly on two steps.
    Section~\ref{subsec::state_of_the_art::building_modeling::building_extraction} presents the different approaches used in the first step: building delineation.
    Afterwhat, the second step consists in modeling the surface of the building.
    Section~\ref{subsec::state_of_the_art::building_modeling::modeling_strategies} presents a general categorization of modeling strategies for buildings.

    \subsection{Building extraction}
        \label{subsec::state_of_the_art::building_modeling::building_extraction}
        In automatic building modeling, in order to model the building surface out of the input sensor data, the building location must first be determined.
        There are actually two ways to approach this problem.
        The first relies on retrieving building footprints out of a \gls{acr::gis} database, such as cadastral ones~\parencite{taillandier2004automatic,durupt2006automatic,horna2007building,ledoux2011topologically,biljecki2017generating,biljecki2019raise}.
        In constrast, the second approach type extracts building outlines directly from the input sensor data~\parencite{poullis2009automatic,lafarge2012creating,nguatem2017modeling,zhu2018large}.
        Both approaches suffer from some shortcomings.

        \paragraph{\gls{acr::gis} databases.}
            The first type of approaches relies on the fact that the \gls{acr::gis} database is acquired at the same time as the sensor data.
            Otherwise, there will be no guaranty that the modeled scene has not changed in the meantime.
            For instance, a building can be removed --- as a whole or partially --- between the two data acquisitions.
            This would result in having terrain or vegetation reconstructed as a building part.\\

            Even if the database is guaranteed to be produced at the same time as the input data, there is another issue that must be dealt with.
            In some datasets, building outlines are actually not stored in their original form: they are instead deformed to fit their specifications.
            For instance, buildings smaller than a certain area can be ommitted.
            The specified generalization level can also play a role as small features could be smoothed away.
            A part from this type of issues, the provided building outlines could be erroneous simply due to a faulty, wether manual or automatic, process.\\
        
        \paragraph{Classification.}
            The second family of building extraction techniques is based on the classification of input sensor data.
            As a consequence, the final building delineation quality depends mostly on the input data.
            Contrarily to the first case, there is no redundancy that can help filter out noise in the data.
            Low density \gls{acr::lidar} point clouds (with a density less than \SI{10}{\pts\per\m \squared}) are, for example, too sparse and unstructured for instance to detect exact boundaries between objects~\parencite{michelin2012building}.
            Conversly, images offer an alternative but, as a passive sensor, can suffer from issues related to shadows (of buildings or other urban objects) that are detrimental to building delineation~\parencite{adeline2013shadow}.\\

            The classification process is not flawless either.
            Just as with \gls{acr::gis} databases, classification relies on some \textit{a priori} information that is generally encoded in regularization terms~\parencite{lafarge2008structural,zhu2018large,zeng2018neural}.
            These are needed to retrieve outlines of buildings efficiently.
            However, they can also fail to represent the ground truth faithfully and results in wrong building footprint extraction.

    \subsection{Modeling strategies}
        \label{subsec::state_of_the_art::building_modeling::modeling_strategies}
        Once the building footprint is extracted, the goal is to generalize its \gls{acr::3d} surface out of the input data.
        Several strategies are conducted.
        They can be classified in three categories: Model-driven, Data-driven and mixed approaches.\\

        \paragraph{Model-driven approaches.}
            This type of methods, also called top-down methods, rely on strong assumptions on the type of buildings to be modeled.
            For example, the Manhattan-world class assumes that buildings are an aggregation of boxes~\parencite{vanegas2010building,ledoux2011topologically,arroyo2015dimension,li2016manhattan}.
            This is actually an instance of grammars utilized in procedural modeling.
            In the latter, a set of predetermined rules are used to determine the best shapes, out of a library, in order to better fit the input data~\parencite{lafarge2008structural,koutsourakis2009single,zhou20102,simon2011random,mathias2011procedural,martinovic2013bayesian,nan2015template,demir2015procedural,zeng2018neural}.
            Top-down approaches are usually used when the input data resolution is not sufficiently accurate to directly retrieve detailed architectural features of the building~\parencite{lafarge2008structural}.

        \paragraph{Data-driven approaches.}
            They can also be called bottom-up methods.
            These modeling techniques need very high resolution sensor data in order to retrieve constituing geometric features of the building.
            This is usually achieved using primitive extraction.
            For instance, building surfaces could be viewed as piecewise-planar structures~\parencite{taillandier2004automatic,chauve2010robust,lafarge2012creating,nan2017polyfit}.
            As a consequence, plane arrangements are drawn from the original data.
            Edges are also examples of features that can be extracted from the data to guide building modeling~\parencite{baillard1999automatic}.
            A second step consists in aggregating the extracted geometric features into a single surface.
            This is usually implemented either through a greedy approach~\parencite{taillandier2004automatic} or a global optimization method~\parencite{poullis2013framework,verdie2015lod,zhu2018large,holzmann2018semantically}.

        \paragraph{Mixed approaches.}
            The first type of methods fails to scale for multiple urban scenes as it is contigent on having a comprehensive enough grammar, which is almost never the case.
            On the other hand, the second kind of methods knows other drawbacks as it mainly tends to oversegment facets in order to stay close to the measured data.
            One way to alleviate these issues is to mix the two approaches.
            \textcite{werner2002new}, for instance, fits predetermined shapes (wedges and rectangles) to already extracted edges and planes.
            However, these usually rely on greedy approaches that do not scale well.\\

        \paragraph{Limitations of current modeling methods.}
            There are still some limitations that these automatic approaches did not adress.
            Higher resolution sensors are yielding more and more data with high frequencies that are still not taken into account as most produced models are at most \gls{acr::lod}-2 ones.
            These can pose serious problems in modeling:~\textcite{bredif20073d} proved that undetected superstructures can lead to bad quality models and their reconstruction can help in that regard.
            High buildings can cast shadows on, or occlude, neighbooring ones which results in issues with their surface retrieval.
            This has not been widely studied~\parencite{lafarge2012creating,bao2013generating}, as buildings are moslty modeled one by one and and often not in challenging\footnote{
                Like buildings delimited by narrow streets or ones with complex architectures.
            } areas.
            All these issues induce defects that should be characterized and classified for a better understanding of the field and, subsequently, objectively understand which methods are the most adapted for which areas.

\section{Quality evaluation of \texorpdfstring{\gls*{acr::3d}}{3D} building models}
    \label{sec::state_of_the_art::quality}
    We have seen previously various methods used to automatically model buildings.
    The goal of this section is to describe the available approaches that evaluate the quality of such models.
    These could be distinguished based on two criteria.\\

    In Section~\ref{subsec::state_of_the_art::quality::output}, are presented the quality evaluation methods based on their output.
    An alternative perspective to characterize quality evaluation methods relies upon the type of reference data (cf. Section~\ref{subsec::state_of_the_art::quality::reference}).
    Based on this survey, we state in details, in Section~\ref{subsec::state_of_the_art::quality::novelty}, how the approach presented in this thesis is different from what was already proposed in the literature.

    \subsection{Output types}
        \label{subsec::state_of_the_art::quality::output}
        We distinguish herein quality evaluation methods depending on the kind of output they produce.
        Fidelity metrics constitues a first instance of output types.
        The second is semantic labels.
        In what follows, we explain, in details, the differences between the two types of method.

        \subsubsection{Fidelity metrics based methods.}
            One way to characterize the quality of a building model is to compute indices or metrics reporting its geometric accuracy.\\

            Most metrics provide information on the geometric precision of the model.
            They are computed for different geometric objects.
            Below, depending on the geometric dimension of the latter, we categorize the geometric fidelity metrics.\\

            We start with zero dimensional objects: i.e., points.
            In this case, metrics are based on their coordinates.
            The goal is to detect positional inaccuraccies~\parencite{kaartinen2005accuracy}.
            In constrast, the choice of points to be inspected is not simple.
            Corner points resulting from the intersection of edges in the model is one choice.
            In fact,~\textcite{zeng2014multicriteria} registers corner points from the evaluated model and the corresponding reference.
            Based on this registration, a comparison is drawn using \acrfull{acr::rmse}, just as in~\parencite{you2011quality,landes2012quality}.
            The same points are used as a proxy for manual quality inspection by~\textcite{elberink2011quality}.
            Another alternative is to sample points from lines or surfaces to be compared.
            These could be predetermined manually as in~\parencite{kaartinen2005accuracy} or sampled regularly as demonstrated by~\textcite{vogtle2003quality,tran2019geometric}.
            Imprecisions are not computed only relying the \gls{acr::rmse}, but can also be separated into planimetric (\gls{acr::lod}-0) and height inaccuraccies (\gls{acr::lod}-1)~\parencite{vogtle2003quality,jaynes2003recognition,kaartinen2005accuracy}.\\

            Second comes edges and all one dimensional objects in general.
            These convey structural, in addition to positional, information.
            \textcite{kaartinen2005accuracy} compare lengths as well as slopes of edges formed by reference points.
            Edge related metrics are also used as an intermediary as shown by~\textcite{elberink2011quality,michelin2013quality}.
            They are both interested in edges resulting from facet intersections.
            While the first relies on \gls{acr::rmse}, the second computes more complex metrics that compares model edges to ones extracted out of sensor data.\\

            Next are compared surfaces (i.e., two dimensional objects), bounded (for example, polygons) or not (like planes).
            These hold more structural information than the first ones and hence are widely used for evaluation.
            \textcite{rottensteiner2014results} used height discrepancy of roof planes so as to evaluate building models.
            This metric is ideal for Manhattan-world model evaluation, as in the case of~\textcite{zebedin2008fusion}.
            In addition to height discrepancy, normal displacement is computed using always the same \gls{acr::rmse} metric by~\textcite{henricsson19973}.
            Conversely,~\textcite{zeng2014multicriteria} use also a \gls{acr::rmse} for comparison, but not in the Euclidean space.
            In fact, after mapping the evaluated and reference models to a sphere, they compare their spherical harmonic~\parencite{brechbuhler1995parametrization} representations.
            Just as with edges, planes can be evaluated using angular measurements, as was proposed by~\textcite{henricsson19973,landes2012quality}.
            Another alternative is to compare reconstructed and reference models based on surface area comparisons.
            These are mostly based on ratios like completeness and correctness\footnote{In other words, recall and precision, respectively.}~\parencite{henricsson19973,schuster2003new,landes2012quality,rottensteiner2014results}.\\

            Last, are three dimensional (i.e., volume) evaluation.
            The same detection ratios that were computed for surfaces are again calculated to evaluate volumes this times, as shown by~\textcite{jaynes2003recognition,mohamed2013quality, zeng2014multicriteria,nguatem2017modeling}.
            These are the only metrics used for volumes that we are aware of.\\

            Regarding \textit{implicit} semantics, as far as we are aware, only one metric is widely used to evaluate its impact.
            As discussed previously in Section~\ref{subsec::introduction::urban_3d_reconstruction::building_3d_modeling}, compaction is one byproduct of semantics.
            As a consequence, it was used as an index to evaluate reconstructions\footnote{It is sometimes called by its antonym: complexity.}: the more a model was compact the better it was.
            This is reflected, for instance, in the work of~\textcite{lafarge2012creating,duan_eccv16,zhang2017deep,zeng2018neural,zhu2018large}, where this metric is never used alone but always alongside geometric ones.

        \subsubsection{Semantic-based methods.}
            \label{subsec::state_of_the_art::quality::output::semantic}
            In a drive to provide a quantitative assessment of building models, the previously defined metrics fail to convey specific and localized information about a predetermined building model.
            These indices are usually used to give a general idea of the quality of models produced by some modeling method.
            Moreover, they do not usually carry semantics, which is critical for further processing steps such as manual correction~\parencite{elberink2011quality}.
            Some evaluation methods, in an effort to alleviate these issues, yield semantic labels that describe the errors of an evaluated model.
            Hereafter, are described the different types of labels that were proposed in the literature.\\

            \parencite{boudet2006supervised} was the first ever work, that we are aware of, which tackles semantic labels as outputs of the evaluation.
            This approach has four classes which indicate how valid the model is: ``acceptable'' and ``correct'' portray valid buildings while ``false'' and ``generalized'' are refused.
            It can be seen as a four grade based score system expressing the confidence in a building model.
            The main limitation of this method is the fact that the proposed labels do not specify what defects a model presents if it is not valid.
            It is, therefore, hard to use for model correction.
            Besides, the acceptable defect definitions depend also on each use case.
            For instance, a communications company would be more adament on the accuracy of roof parts, which would affect wave propagation, rather than an insurance company interested in flood damage estimation.
            This means that each use case implies a relabeling that could be potentially different from other one.
            \textcite{durupt2006automatic} used also the same labels to evaluate their reconstruction.\\
            
            The first hints of a fine grained semantic labeling of building model errors lay in the work of~\textcite{rottensteiner2014results}.
            This work was the first to report segmentation issues, at facet level, in labels instead of a global ratio.
            They distinguish between oversegmentation cases, undersegmentation cases and cases where both co-occur.\\

            On the other hand, these mentioned errors are not comprehensive: they do not cover all possible building model errors.
            \textcite{michelin2013quality} came up with a richer taxonomy of errors that are categorized into three big families:
            \begin{description}
                \item[Footprint errors:] these portray errors relative to the building footprint, which is used by many modeling algorithms as input.
                        Errors contained in this family are: ``erroneous outline'', ``unexisting building'', ``missing inner court'' and ``inaccurate footprint''.
                \item[Reconstruction errors:] these are caused by the modeling approach.
                        These defects can be the result of the incompatibility of some \textit{a priori} hypotheses about the scene, for instance.
                        Such errors are: ``under-segmentation'', ``over-segmentation'', ``inaccurate roof'' and ``Z translation''.
                \item[Vegetation errors:] this corresponds to a special case when modeled building are occluded, completely or partially, by higher vegetation.
                        It becomes impossible to evaluate properly these models.
            \end{description}
            Although the last taxonomy is rich, it is not exhaustive enough as it misses cases that are not present in the urban zone that was studied in the paper.
            For instance, the fact of modeling a cone-shaped roof with a piecewise-planar structure is not taken into account in this taxonomy.
            Moreover, it adopts the point of view of the modeling method that was used to provide their dataset.
            Knowing the specific weaknesses of the latter guided the choice of error family classification and the error definitions.
            This is particularly clear when looking at their error categorization.
            In fact, the first error class relates to the fact that the used building modeling approach~\parencite{durupt2006automatic} relies on footprints given as input.
            The second category corresponds to the actual step of building roof structure inference.

    \subsection{Types of reference data}
        \label{subsec::state_of_the_art::quality::reference}
        In order to evaluate models, reference data are utilized for comparison.
        Based on the latter, another way to discriminate among modeling methods is possible.
        The first class of reference data are high quality ground truth \gls{acr::3d} building models.
        Remote sensing data is the second alternative that is used for reference.
        Neither of these two choices do influence the type of output the evaluation method produces.
        Hereafter, is explained the difference between the two categories.

        \subsubsection{High resolution ground truth.}
            Ground truth building models are mainly acquired manually.
            Herein, are listed the different ground truth measurement techniques, in descending order of accuracy.\\

            The most obvious case consists in field measurements of the modeled building.
            \textcite{dick2004modelling}, for instance, evaluated their buildings based on manual tape measurements taken on specific architectural features, like windows and columns, with an accuracy of \SI{0.01}{\m} for the first and \SI{0.1}{\m} for the second.
            Complete and scalable measurements of buildings are possible using topographic surveys.
            Using the latter, building models could be reconstructed with precision up to \SI{\pm 0.1}{\m}~\parencite{henricsson19973} or \SI{\pm 0.05}{\m}~\parencite{vogtle2003quality}.\\
            There is also the possibility of manually modeling the building using overhead images, or stereoplotting.
            ~\textcite{zebedin2008fusion} use such a method to produce their reference data from aerial images with an accuracy up to the order of \SI{\pm 0.15}{\m}.
            The same procedure was used also by~\textcite{jaynes2003recognition} producing models with inaccuraccies bounded by \SI[fraction-function = \sfrac]{\pm 1/3}{\m}.

        \subsubsection{Remote sensing data.}
            Reference ground truth models are not readily available at large quantities~\parencite{schuster2003new}.
            The previous choice is hard to scale up to district or city levels.
            In fact, they are more suitable to evaluate few building models: e.g., in order to validate a reconstruction method.
            Conversely, remote sensing data are more accessible and could be used, instead, as reference.
            In fact, since these are usually fed as input in modeling methods, it is only reasonable to evaluate the produced models in comparison to the input.
            Listed here, are the different types of remote sensing data and how they could be used for building model evaluation.\\

            \paragraph{Aerial images.}
                These could be original images or preprocessed orthoimages.
                The first class of images are the most precise but the other one is more available.
                Images were used by~\textcite{michelin2013quality} to extract \gls{acr::3d} segments based on plane sweeping techniques.
                Reference edges are filtered out and are used to evaluate the \gls{acr::3d} model (intersection) edges.
                Based on these segments,~\textcite{boudet2006supervised} not only evaluate edges but also corners (i.e., edge intersections) and planes.
                Facets were also evaluated, in~\parencite{boudet2006supervised}, based on correlation functions computed from multiple overlapping overhead images.
                Orthoimages were used also to, for instance, compute \gls{acr::ndvi} scores for vegetation occluded building model discrimination.

            \paragraph{\gls{acr::lidar} point clouds.}
                This type of data have the inherent advantage, compared to images, of directly providing depth information.
                \textcite{kaartinen2005accuracy} used data that was acquired multiple times with a guaranteed precision up to \SI{0.083}{\m} in planimetry and \SI{0.035}{\m} in height.
                Out of the latter were chosen reference points that were compared to equivalents in the evaluated building models (check the previous Section).
                All the points could also be used for comparison by computing metrics such as \gls{acr::rmse}~\parencite{lafarge2012creating,zhu2018large}.
                Original input data is not always accessible.
                One other issue arises when using data from multiple sources where it has to be coregistred in the same reference system.
                This is taken into account by~\textcite{akca2010quality}, before addressing the completeness of building models.
            
            \paragraph{Height maps.}
                These are not sensor data as they are a byproduct of earlier data types.
                Still, they are considered here since they are used as input by some building modeling pipelines.
                Just like with \gls{acr::lidar} point clouds, \gls{acr::dsm} is used for building model comparison based on \gls{acr::rmse}~\parencite{zeng2018neural}.
                \textcite{michelin2013quality}, however, use the same data but differently.
                In fact, \gls{acr::dsm}, being a result of overhead images, can be used as proxy, to help extracting \gls{acr::3d} geometric features instead of recomputing correlation scores like in~\parencite{boudet2006supervised}.
                It can also be valuable for missing court detection by calculating sky viewshed angle scores~\parencite{michelin2013quality}.

    \subsection{Novelty of the proposed method}
        \label{subsec::state_of_the_art::quality::novelty}
        Quality evaluation approaches presented hereinabove are mostly unsuitable for the stated objectives in Section~\ref{subsec::introduction::contributions::positioning}.\\

        In fact, the semantic character of the evaluation overrules approaches relying only on geometry based metrics.
        This represents most of the methods discussed earlier (cf. Section~\ref{subsec::state_of_the_art::quality::output}).
        Actually, these metrics could be used once a semantic error is identified to help quantify the defect.
        Conversely, the need for reasonably available reference data, which is dictated by the \textbf{large-scale} constraint, implies the reliance on remote sensing data based methods (cf. Section~\ref{subsec::state_of_the_art::quality::reference}).\\

        There are only two approaches that are both semantic and rely only on more readily available remote sensing data:~\parencite{boudet2006supervised,michelin2013quality}.
        Both define semantic errors that are predicted with the help of overhead images and \glspl{acr::dsm}.
        A classifier learns statistical properties of the \gls{acr::3d} building models using features that are derived from these sensor data.
        The learning process further helps scaling the evaluation pipeline to unseen data by predicting errors using the same attributes.\\

        Our work relies on the same idea, but goes further by allowing the possibility to evaluate building models without using any reference data\footnote{With the exception of training data.} and relying on their intrinsic attributes instead.
        It also offers a new taxonomy of errors that is intended to be exhaustive and generalizable.
        These latter notions are developed in details in Chapter~\ref{chap::semantic_evaluation}, while Chapter~\ref{chap::learned_evaluation} presents how features are chosen to represent building models and the learning process.\\

        In fact, we propose a novel hierarchical and modular taxonomy that assembles all possible semantic and geometric errors that can affect the building model.
        Based on this taxonomy, depending on the end user needs, error labels are extracted for the classification.
        We also developed a baseline of features, intrinsic as well as extrinsic\footnote{If available.}, which describe the evaluated models.
        Using these features so as to train some regular off-the-shelf classifiers, we proved the feasibility of our approach.
        Finally, we made use of some advanced feature extractors with the aim of improving the prediction scores of the proposed pipeline.
