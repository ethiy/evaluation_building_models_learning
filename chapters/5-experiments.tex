\minitoc

\vfill

In Chapters~\ref{chap::semantic_evaluation} and~\ref{chap::learned_evaluation}, we proposed a semantic quality evaluation of building \gls{acr::3d} models employing a learning formulation.
Herein, we put our pipeline to the test.
First, in Section~\ref{sec::experiments::datasets}, we delineate how the building models, that are used for the study, were obtained.
Second and last, Section~\ref{sec::experiments::baseline_feature_analysis} provides a first experimental outlook of the capacity of our approach to detect errors affecting building \gls{acr::3d} models.

\clearpage

\section{Datasets}
    \label{sec::experiments::datasets}
    In this section, we present the studied building models.
    Section~\ref{subsec::experiments::datasets::scenes} describes the selected urban scenes as well as the modeling technique which helped produce the studied models.
    Next, in Section~\ref{subsec::experiments::datasets::stats}, we analyse the distribution of the previously defined errors (cf. Chapter~\ref{chap::semantic_evaluation}) over the three urban areas of interest.
    
    \subsection{Urban scenes and modeling techniques}
        \label{subsec::experiments::datasets::scenes}        
        \gls{acr::3d} models from three different cities of France are selected in order to assess the performance of our framework: \textbf{Elancourt}, \textbf{Nantes}, and the XIII\textsuperscript{th} district of Paris (\textbf{Paris-13}) (cf. Figure~\ref{fig::france_map}).
        Figure~\ref{fig::elancourt_ortho} depicts the small city of \textbf{Elancourt} which contains diverse of building types: residential areas with gable and hip roof buildings and large industrial flat roof building based districts (cf. Figure~\ref{subfig::elancourt_samples}).
        \textbf{Nantes}, as shown in Figure~\ref{fig::nantes_ortho}, represents a denser urban setting but with a lower building diversity (cf. Figure~\ref{subfig::nantes_samples}).
        In Figure~\ref{fig::paris-13_ortho}, one can see how \textbf{Paris-13} consists of mostly flat roof high towers which coexist with Haussmann style buildings that typically exhibit highly fragmented roofs (cf. Figure~\ref{subfig::paris-13_samples}).
        The \textbf{Elancourt} (\textit{resp.} \textbf{Nantes} and \textbf{Paris-13}) scene contains 2,009 (\textit{resp.} 748 and 478) annotated building models.
        In order to handle these models, \verb!proj.city!\footnote{
            \href{https://github.com/ethiy/proj.city}{\verb!proj.city!: https://github.com/ethiy/proj.city.git}
        }, a C++ library, was developped making use of the CGAL library~\parencite{fabri2000design}.
        Thanks to this tool, we can project building models in the nadir direction as well as produce their height maps.
        The \gls{acr::dsm} and the orthorectified image spatial resolution is \SI{0.06}{\m} for the first area while it is \SI{0.1}{\m} for the other ones.\\

        \begin{figure}[htpb]
            \ffigbox[\textwidth]{
                \includegraphics[width=.75\textwidth]{images/datasets/france_map}
            }{
                \caption[
                    Map of France showing the studied urban scenes.
                ]{
                    \label{fig::france_map}
                    Map of France showing the studied urban scenes.
                    Each square corresponds to a city:
                    \textcolor[rgb]{.84,.1,.11}{\(\blacksquare\)} \textbf{Paris-13}, \textcolor[rgb]{1,.79,.5}{\(\blacksquare\)} \textbf{Elancourt}, \textcolor[rgb]{.17,.51,.73}{\(\blacksquare\)} \textbf{Nantes}.
                }
            }
        \end{figure}

        \begin{figure}[htpb]
            \ffigbox[\FBwidth]{
                \includegraphics[width=\textwidth]{images/datasets/elancourt_global}
            }{
                \caption{
                    \label{fig::elancourt_ortho}
                    Orthoimage showing the diversity of buildings in Elancourt.
                }
            }
        \end{figure}

        \begin{figure}[htpb]
            \ffigbox[\FBwidth]{
                \includegraphics[width=\textwidth]{images/datasets/nantes_global}
            }{
                \caption{
                    \label{fig::nantes_ortho}
                    Orthoimage depicting the dense city center of Nantes.
                }
            }
        \end{figure}

        \begin{figure}[htpb]
            \ffigbox[\FBwidth]{
                \includegraphics[width=\textwidth]{images/datasets/paris-13_global}
            }{
                \caption{
                    \label{fig::paris-13_ortho}
                    Orthoimage showing the heterogeneity of the XIII\textsuperscript{th} district of Paris.
                }
            }
        \end{figure}

        \begin{figure}[htpb]
            \ffigbox[\textwidth]{
                \begin{subfloatrow}[3]
                    \ffigbox[\FBwidth]{
                        \includegraphics[width=.3\textwidth]{images/datasets/elancourt_samples}
                    }{
                        \caption{
                            \label{subfig::elancourt_samples}
                            Elancourt contains flat roof buildings (top) as well as gable roof ones (bottom).
                        }
                    }
                    \ffigbox[\FBwidth]{
                        \includegraphics[width=.3\textwidth]{images/datasets/nantes_samples}
                    }{
                        \caption{
                            \label{subfig::nantes_samples}
                            Nantes exhibits high rising towers (top) along side densely packed fragmented roof buildings (bottom).
                        }
                    }
                    \ffigbox[\FBwidth]{
                        \includegraphics[width=.3\textwidth]{images/datasets/paris-13_samples}
                    }{
                        \caption{
                            \label{subfig::paris-13_samples}
                            The XIII\textsuperscript{th} district of Paris is made of Haussmannian buildings (top) and high rising towers bottom).
                        }
                    }
                \end{subfloatrow}
            }{
                \caption{
                    \label{fig::samples}
                    Samples of building types per area of interest.
                }
            }
        \end{figure}

        \gls{acr::3d} models were generated using the algorithm described in~\parencite{durupt2006automatic}, out of existing building footprints and aerial VHR multi-view \glspl{acr::dsm}.
        The modeling algorithm simulates possible roof structures with facets satisfying some geometric constraints.
        The best configuration is selected using a scoring system on the extrapolated roofs.
        Finally, vertical building fa\c{c}ades connect the optimal roof to the building footprint.
        These models have a \gls{acr::lod}-2 level.
        This method is adapted to roof types of low complexity and favors symmetrical models that are common in residential areas.
        It has been selected to ensure a varying error rate for the three areas of interest, especially since models were generated with partly erroneous cadastral maps.
        Consequently, the modeling will fail, allowing to tackle the evaluation of the ensuing models.
        3,235 buildings in total are considered.
        They were annotated according to the atomic errors list provided by our taxonomy.

    \subsection{Error statistics}
        \label{subsec::experiments::datasets::stats}
        \begin{figure}[htpb]
            \centering
            \ffigbox[\textwidth]{
                \begin{subfloatrow}[2]
                    \centering
                    \ffigbox[.5\textwidth]{
                        \includestandalone[mode=buildnew, height=7.5cm]{figures/datasets/families_stats}
                    }{
                        \caption{
                            \label{fig::family_errors}
                            Occurence statistics for error families and the \texttt{Unqualified} class computed for each area.
                        }
                    }
                    \ffigbox[.5\textwidth]{
                        \includestandalone[mode=buildnew, height=7.5cm]{figures/datasets/lod1_stats}
                    }{
                        \caption{
                            \label{subfig::lod1_errors}
                            Occurence statistics for \texttt{Building errors} depending on the area of study.
                        }
                    }
                \end{subfloatrow}
                \vskip1em
                \begin{subfloatrow}
                    \centering
                    \ffigbox[\textwidth]{
                        \includestandalone[mode=buildnew, width=.7\textwidth]{figures/datasets/lod2_stats}
                    }{
                        \caption{
                            \label{subfig::lod2_errors}
                            Occurence statistics for \texttt{Facet errors} depending on the area of interest.
                        }
                    }
                \end{subfloatrow}
            }{
                \caption[
                    Detailed error statistics depending on the urban scenes.
                ]{
                    \label{fig::error_statistics}
                    Detailed error statistics depending on the urban scenes.
                    The height of bars indicates the frequency of each errors while the number of occurences is displayed over.
                }
            }
        \end{figure}

        Some of the models obtained using the previous datasets were manually annotated manually in order to build training datasets.
        To annotate a building model, the manual operator compares the nadir projection of the model to the corresponding orthoimage and \gls{acr::dsm}.
        This was possible thanks to the work\footnote{\href{https://github.com/CHUPClem/sGrISner}{sGrISner: https://github.com/CHUPClem/sGrISner}} of Cl√©mence Chupin, who was a Master student at \gls{acr::ensg}.
        She develops a pyQT interface in order to ease the task.
        This allows to switch between data sources and better assess the errors affecting each building.
        Figure~\ref{fig::error_statistics} reports modeling errors statistics over the annotated buildings.\\

        These statistics are first analysed depending on the family errors at the \texttt{finesse} = 2 level (cf. Figure~\ref{fig::family_errors}).
        Due to the fact that geometrically inconsistent \gls{acr::3d} models were filtered out in a preprocessing (nadir projection) step, \texttt{Unqualifiable} buildings represent a small fraction of the dataset (less than \SI{7.5}{\percent}).
        Actually, this latter corresponds to the, partially or completly, occluded buildings that could not be qualified.
        Moreover, only a small fraction of buildings are \texttt{Valid}:
        57 (\SI{2.84}{\percent}) in \textbf{Elancourt}, 55 (\SI{7.35}{\percent}) for \textbf{Nantes} and 21 (\SI{4.39}{\percent}) in \textbf{Paris-13}.
        Most buildings are affected by the \texttt{Building Errors} family (over \SI{58.16}{\percent}) and the \texttt{Facet Errors} one (over \SI{75.94}{\percent}).\\

        At the \textbf{\gls{acr::efin}} level 3, two axes of analysis are possible.
        First, we group errors that are very frequent in the dataset.
        Over-segmentation errors (\texttt{FOS} and \texttt{BOS}), in both error families, are well represented ranging from \SIrange{38.9}{66.8}{\percent}.
        The same is true for \texttt{FIG} with a frequency from \SIrange{59.8}{80}{\percent}.
        \texttt{FIT}, on the other hand, are very rare in all the areas with ratios a little less than \SI{1.5}{\percent}.
        The rest have a presence ratio within the percentage interval of [10, 30].
        The errors that are rare are understandably going to negatively impact the learning process.\\
        
        Secondly, we can compare error frequency discrepancies depending on the studied scene.
        \textbf{Elancourt} is different compared to the relatively close sets \textbf{Nantes} and \textbf{Paris-13}, with regards to \texttt{BOS}, \texttt{BUS} and \texttt{BIT}.
        In fact, the last two areas are more densely urbanized than the first one exhibitting the same properties at \gls{acr::lod}-0.
        \texttt{BIB}, on the other hand, are equally distributed over the different datasets as it depends mostly on the input sensor data resolution independently of building types.\\
        At the facet level, \texttt{FIT} is also equally occuring across all the scenes different from the rest of \texttt{Facet errors}.
        In fact, \texttt{FOS} occurence ratio is related to the size of facets in urban scenes.
        Actually, the less complex roof structures are, the more big are facets and the more chance they have to be over segmented.
        Indeed, \textbf{Elancourt}, \textbf{Nantes} and \textbf{Paris-13} scenes are ordered in an ascending manner of their roof structure complexity.
        Conversely, in line with the previous analysis, \texttt{FUS} are less present in \textbf{Elancourt} than in \textbf{Nantes} which, in turn, contains less of the same error than \textbf{Paris-13}.
        \texttt{FIB} is distributed in the same manner as \texttt{FUS}.
        This is mainly due to the fact that the more a roof structure is complex the more precision errors are possible.
        \texttt{FIG} does not keep the same dynamic as its frequency keeps stable from \textbf{Elancourt} and \textbf{Nantes} but jumps considerably in \textbf{Paris-13}.
        This may be explained by the fact that the gap in \texttt{FUS} error ratios between \textbf{Paris-13} and \textbf{Nantes} is more important than that of \texttt{FOS} errors, contrarily to the same gaps for the same errors between \textbf{Nantes} and \textbf{Elancourt} which compensate each other.

\section{The experimental set-up}
    \label{sec::experiments::setup}
    In this section, we give detailed account of how every ingredient of our pipeline is parameterized.
    We first start, in Section~\ref{subsec::experiments::setup::feature_configurations}, by specifying the different feature configurations that are used in the experimental study and how there were implemented.
    Next, in Section~\ref{subsec::experiments::setup::classification}, we discuss in detail how the classification process was conducted.

    \subsection{Feature configurations}
        \label{subsec::experiments::setup::feature_configurations}
        We present herein the features that were used in experiments.
        First, we try to prove the efficiency of the proposed learning framework.
        Hence, we test different configurations using the baseline features.
        Secondly, more advanced features are fed into the pipeline.
        Consequently, new possible combinations are discussed.

        \subsubsection{Baseline features}
            The geometric features are intrinsic and are always available.
            As a consequence, we tested four feature configurations: ``geometric features'' (\textbf{Geom.}) only, ``geometric and height features''(\textbf{Geom. \(\oplus\) Hei.}), ``geometric and image features''(\textbf{Geom. \(\oplus\) Im.}) as well as ``geometric, height and image features''(\textbf{All}).
            In order to have a better understanding of how important each modality is, their feature vectors are by design drawn to be of the same size: 20.\\
            Actually, using the function \(\chi_{\max,\min,\operatorname{mean},\operatorname{med}}\) defined in Equation~\ref{eq::max_min_mean_med_extractor}, the geometric feature vector in Equation~\ref{eq::geometric_features} is of dimension
            \begin{equation*}
                \underbrace{4}_{\substack{\text{the output dimension}\\\text{of the function } \chi_{\max,\min,\operatorname{mean},\operatorname{med}} }} \times \underbrace{5}_{\substack{\text{the number of the facet}\\\text{graph attributes}}} = 20.
            \end{equation*}
            Regarding height based feature vectors, their dimension depend on the histogram parameters.
            Since we compute differences between observed and model height at terrain level also (cf. Section~\ref{subsec::learned_evaluation::baseline::height}), and because these are virtually unbounded and can differ from one scene to another, the maximum possible discrepancy is limited to \SI{\pm 50}{\m} for all scenes.
            In order to have the same feature vector dimension for this modality as for the geometric one, the number of bins is fixed manually to \(20\).\\
            For image based features, the cosine similarity between normal vectors, used in Equation~\ref{eq::corr_fac}, is by definition bounded in the interval [-1, 1].
            This interval is consequently divided evenly into \(20\) bins for the histogram computation.
            The \glspl{acr::dsm} and orthorectified images used to derive height and image features have the same spatial resolution as the reconstruction input data.\\

            These features implementation is conducted in Python and is not optimized.
            Geometric features are computed in average in \SI{0.05}{\s \per \building}, height based ones take in average \SI{1.4}{\s \per \building} and finally image based ones need more than \SI{69}{\s \per \building}.
            In order to reduce the runtime of each experiment, the last two types of features are cached once computed for a building model and retrieved latter for tests.

        \subsubsection{Advanced features}
            Baseline features are replaced by more advanced ones as shown in Section~\ref{sec::learned_evaluation::richer_features}.
            These are denoted as follows:
            \begin{itemize}[label=\(\blacktriangleright\)]
                \item \textbf{S-Hei.} refers to \gls{acr::scatnet} height based features;
                \item \textbf{S(d)-Im.} (\textit{resp.} \textbf{S(c)-Im.}) corresponds to \gls{acr::scatnet} image based features with \texttt{deletion} (\textit{resp.} \texttt{channel}) option;
                \item \textbf{S(d)-All} (\textit{resp.} \textbf{S(c)-All}) \(\equiv\) \textbf{Geom.} + \textbf{S-Hei.} + \textbf{S(d)-Im.} (\textit{resp.} \textbf{S(c)-Im.});
                \item \textbf{K-S(d)-All} (\textit{resp.} \textbf{K-S(c)-All}) \(\equiv\) \textbf{K-Geom.} + \textbf{S-Hei.} + \textbf{S(d)-Im.} (\textit{resp.} \textbf{S(c)-Im.});
            \end{itemize}
            We lay out herein how their parameters were determined.

            \paragraph{Graph kernels}
                In Section~\ref{subsec::learned_evaluation::richer_features::graph}, we have seen how 14 graph kernels are aggregated to describe graphs.
                We relied, in experiments, on an available Python module called GraKel~\parencite{siglidis2018grakel}.
                We provide herein the parameters of each kernel type.
                \begin{description}
                    \item[\(\blacktriangleright\) Random walk] The exponential version fails numerically and was left out.
                                After a grid search \(\lambda\) was set to be \num[scientific-notation = true]{1e-3}, for the geometric random walk.
                                This is actually a very low value as \(\lambda\) has to verify the condition stated in Equation~\ref{eq::condition_geometric_kernel_convergence} for all pairs of graphs in the training dataset.
                                One case where the largest eigenvalue of the direct product of the adjacency matrix of two graphs in the dataset suffices to considerably lower the maximal value \(\lambda\) can take.
                                To compute such a kernel it takes approximatly \SI{1.14}{\s\per\building\squared}.
                    \item[\(\blacktriangleright\) \gls{acr::svm} \(\vartheta\)] This kernel takes no parameters.
                                It takes on average \SI[scientific-notation = true]{0.0000201}{\s\per\building\squared} to compute a kernel comparison.
                    \item[\(\blacktriangleright\) Multiscale Laplacian] Our building models have a varying number of nodes from 4 up to 20 and more facets in some cases.
                                That is why we choose to keep the same radius size\footnote{The neighboorhoods \(N_l(v)\) are taken as balls around vertex \(v\)~\parencite{kondor2016multiscale}.} and depth level \(L\) set to 3 as in the original paper~\parencite{kondor2016multiscale}.
                                The same goes for the regularization terms fixed at a value of \num[scientific-notation = true]{1e-2}.
                                Computing one kernel comparison requires around \SI{10.6}{\s\per\building\squared}.
                    \item[\(\blacktriangleright\) Propagation] The choice of the transition matrix, as explained in Section~\ref{subsubsec::state_of_the_art::mlpr::feature_extraction::graph_classification}, is set by default to be the normalized adjacency matrix.
                                The maximal iteration number \(t_{\max}\) is similar to the height parameter of the Weisfeler-Lehman kernel and is set to 5.
                                Other parameters regarding the hashing and binning processed are kept at their default values.
                                Comparing two instances takes around \SI[scientific-notation = true]{0.0812}{\s\per\building\squared}.
                    \item[\(\blacktriangleright\) Graph hopper] This kernel takes no other parameter than the choice of base kernels.
                                Comparisons between takes on average \SI{34.5}{\s\per\building\squared}.
                \end{description}

            \paragraph{\gls*{acr::scatnet}}
                For \glspl{acr::scatnet}, we rely on a modern and vestatile Python module: Kymatio~\parencite{andreux2018kymatio}.
                The parameterization of the \gls{acr::scatnet} does not depend on the signal content as much as it relates to the size of input images.
                This is true because the filter banks, which parameterization is the most related to the signal dynamics, were set beforehand.
                As a consequence, the same parameters were applied for image and height based features.\\

                The number of possible orientations \(L\) is fixed at its default value 8 as it was the optimal choice corresponding to the already defined Morlet filter banks.
                \(I\) the scale of the \gls{acr::scatnet} pooling operator was set to 3.
                This corresponds to models \(\mathsf{M}\) verifying: \(w_{\mathsf{M}} \geq 2^3 = 8\) and \(h_{\mathsf{M}} \geq 8\).
                In \textbf{Elancourt}, it implies that building models have to be at least larger in length and width than \SI{8 x 0.06}{\m} = \SI{0.48}{\m}, while in \textbf{Paris-13} and \textbf{Nantes} the minimal dimensions of a building are \SI{8 x 0.10}{\m} = \SI{0.80}{\m}.
                This is reasonable and fails only for some rare cases were the building is obviously over segmented an can be detected as such by simply applying a building model size threshold.\\
                The maximal number of layers \(m\) is 2.
                As a consequence, the total number, according to Equation~\ref{eq::scatnet_number_paths} of scattering outputs is \(n_S = 217\).
                This implies that the length of \gls{acr::scatnet} based features is \(d \times n_S\) = \num{5 x 217} = 1085 per channel.\\

                The Kymatio implementation of \gls{acr::scatnet} uses GPU to accelerate computations.
                Using an NVIDIA GeForce GTX 750 Ti graphics card, it takes around \SI{14.06}{\s \per \building} on average to compute a height based features and \SI{20.86}{\s \per \building}.
                As with previous features onces, once computed they are cached for latter use.

    \subsection{Classification settings}
        \label{subsec::experiments::setup::classification}
            Feature extractors were defined in the previous subsection.
            Herein, are given extensive details how the considered classifiers (cf. Section~\ref{subsec::learned_evaluation::classification::classifiers}) are applied.
            We also provide the metrics that will help measure the accuracy of predictions.

        \subsubsection{Considered labels}
            All \textbf{\gls{acr::efin}} levels were tested.
            The input models are generalized to \gls{acr::lod}-2.
            As a consequence, we chose \textbf{\gls{acr::elod}} = \gls{acr::lod}-2.
            If the \textbf{exclusivity} is \textsc{on}, at \textbf{\gls{acr::efin}} level 3, the second stage classification results depends on the first one.
            After a brief experimental study, the first stage did not yield good enough results in order to test this configuration.
            In fact, we remind the reader that, at this stage, our goal is, first and foremost, to prove the feasability of the proposed approach.
            That is why we limited the experiments to the case where the \textbf{exclusivity} is set to be \textsc{off}.

        \subsubsection{Classifiers}
            As discussed in Section~\ref{subsec::learned_evaluation::classification::classifiers}, two classifier types were considered in the experimental study.
            As already explained beforehand in Section~\ref{subsec::learned_evaluation::classification::classifiers}, a one-vs-all approach is used to adapt \glspl{acr::rf} to multi-label settings.
            The same approach was chosen to accommodate \glspl{acr::svm} to both the multi-class and the multi-label possibilities.
            We relied upon the already available and ubequitous implementation in Python~\parencite{scikit-learn}.
            Below we detail quantitavely the used parameters.
            
            \paragraph{\acrshort*{acr::rf}}
                A standard grid search involving a smaller set of building models and only baseline geometric features~\parencite{ennafii2018qualificationunannotated} yielded comparable results for the number of trees set in the range \numrange{850}{1000} and a maximum tree depth from \numrange{3}{5}.
                Given the already immense parameter search space involving all possible feature configurations, feature extraction parameters and label possibilities, the \gls{acr::rf} parameters are set to \num{1000} for the tree number and 4 for the maximum tree depth for all other experiments without performing any grid search.
                Since this classifier model is easier to parameterize than the other, it will always be used in experiments unless said otherwise.

            \paragraph{\acrshort*{acr::svm}}
                The linear \gls{acr::svm} is not well suited for the type of features that we use, even for baseline features as experiments do not yield any results in time.
                As a consequence, the latter was left out and we experimented only with the kernel \gls{acr::svm} using the standard \gls{acr::rbf} kernel (cf. Equation~\ref{eq::rbf_kernel}) when instances are vectors not graphs.
                Just as with the \gls{acr::rf} classifier, we conducted a grid search using baseline geometric features only in order to determine both parameters \(C\) and \(\gamma\) by limiting the range between \numrange[range-phrase={ and }, scientific-notation = true]{1e1}{1e-3} for both.
                All values yielded sensibly the same scores.
                As a result we set these parameters as follows: \(C = \num[scientific-notation = true]{1e-1}\) to not overpenalize nor underfit during learning and \(\gamma = \num[scientific-notation = true]{1e-3}\) to avoid overfitting.
                Regarding \gls{acr::mkl}, we made use of the already implemented EasyMKL~\parencite{aiolli2015easymkl} approach.
                It was the only method, to our knowledge that was readily available library in Python\footnote{\href{https://github.com/IvanoLauriola/MKLpy}{MKLpy: https://github.com/IvanoLauriola/MKLpy}}.
    
        \subsubsection{Metrics for quantitative assessment}
            The overall accuracy is not interesting due to the highly unbalanced label distribution.
            We prefer reporting recall \(\bm{Rec}\) and precision \(\bm{Prec}\) ratios.
            As a reminder these metrics are defined as follows:
            \begin{align}
                \label{eq::recall_precision}
                \bm{Rec} &\triangleq \frac{tp}{tp + fp}\\
                \bm{Prec} &\triangleq \frac{tp}{tp + fn},
            \end{align}
            where:
            \begin{conditions}
                tp & the number of instances predicted positive that are positive in reality;\\
                fp & the number of instances predicted positive that are negative in reality;\\
                fn & the number of instances predicted negative that are positive in reality.
            \end{conditions}
            Recall expresses, from a number of samples of a given class, the proportion that was rightfully detected as such.
            Precision indicates how much samples, amongst the detected ones, were, in truth, part of the studied class~\parencite{powers2011evaluation}.
            We also summarize these two ratios with their harmonic mean, the F-score:
            \begin{equation}
                \label{eq::f_score}
                \bm{F_{score}} \triangleq \frac{2}{\frac{1}{\bm{Rec}} + \frac{1}{\bm{Prec}}}.
            \end{equation}
            Unless said otherwise, all experiments were conducted performing a 10-fold cross validation to avoid overfitting or underfitting issues.
            Only test results are reported.

\section{Baseline feature analysis}
    \label{sec::experiments::baseline_feature_analysis}
    In the previous sections, we have shown how our dataset of building models was assembled and how the urban scene composition influences modeling error statistics.
    We also specified in details how each bloc of the pipeline was set up.
    At this stage, our aime is to prove the feasablity of the approach proposed in Chapter~\ref{chap::learned_evaluation}.
    As a consequence, for now, we limit ourselves to using the baseline features.\\

    First, in Section~\ref{subsec::experiments::baseline_feature_analysis::rmse}, the \gls{acr::rmse} is proven to be inadequate for detecting errors in our taxonomy.
    Secondly, prediction results from all possible configurations of baseline features are compared in Section~\ref{subsec::experiments::baseline_feature_analysis::ablation}.
    Third and last, Section~\ref{subsec::experiments::baseline_feature_analysis::feature_importance} concludes the analysis by studying the feature importance, for all training zones.

    \subsection{\texorpdfstring{\acrlong*{acr::rmse}}{RMSE} predictive capacity}
        \label{subsec::experiments::baseline_feature_analysis::rmse}
        The \gls{acr::rmse} is the standard measure in most of \gls{acr::3d} modeling methods.
        As a consequence, we use it herein as a reference that our baseline is to be compared to.
        We train the classifier on Elancourt with the one dimensional feature vector containing the \gls{acr::rmse}.
        This scene was sufficient enough for our analysis.
        Mean test results are shown in Table~\ref{tab::rmse_results}.\\

        \begin{table}[htpb]
            \footnotesize
            \begin{tabular}{c c c c c c c c c c}
                \toprule
                & \texttt{BOS} & \texttt{BUS} & \texttt{BIB} & \texttt{BIT} & \texttt{FOS} & \texttt{FUS} & \texttt{FIB} & \texttt{FIT} & \texttt{FIG} \\
                \midrule
                \(\bm{Rec}\) & 99.55 & 0.21 & 0 & 0 & 98.68 & 0.63 & 0 & 0 & 98.15 \\
                \midrule
                \(\bm{Prec}\) & 68.78 & 33.33 & --- & 0 & 66.60 & 0.25 & --- & 0 & 61.15 \\
                \midrule
                \(\bm{F_{score}}\) & 81.35 & 0.42 & 0 & 0 & 79.52 & 1.24 & 0 & 0 & 75.36 \\
                \midrule
                \(\bm{Acc}\) & 68.46 & 75.65 & 89.57 & 94.66 & 66.36 & 83.62 & 88.24 & 98.36 & 60.86 \\
                \bottomrule
            \end{tabular}
            \caption[
                \textbf{\gls{acr::efin}} 3 error prediction results using the \gls{acr::rmse} on \textbf{Elancourt}.
            ]{
                \label{tab::rmse_results}
                \textbf{\gls{acr::efin}} 3 error prediction results using the \gls{acr::rmse} on \textbf{Elancourt}.
                \(\bm{Acc}\) expresses the overall accuracy ratio.
            }
        \end{table}

        We can distinguish two groups of errors: 
        \begin{itemize}[label=\(\blacktriangleright\)]
            \item \texttt{BOS}, \texttt{FOS} and \texttt{FIG}: these have a high recall and a low precision and overall accuracy;
            \item \texttt{BUS}, \texttt{BIB}, \texttt{BIT}, \texttt{FUS}, \texttt{FIB} and \texttt{FIT}: these have low recall and precision ratios.
        \end{itemize}
        The first (\textit{resp.} second) group coincides exactly with errors that affect more (\textit{resp.} less) than half of the buildings.
        For this kind of errors, the classifier assigns to almost all samples the positive class.
        In fact, we end up with a high ratio of false positives (false alarms) and hence a high recall ratio that is coupled with a weak precision and overall accuracy.
        Exactly the inverse happens with the rest of the errors as we obtain a high percentage of false negative.
        We can safely conclude that the \gls{acr::rmse} is not able to detect errors defined in our taxonomy.

    \subsection{Feature ablation study}
        \label{subsec::experiments::baseline_feature_analysis::ablation}
        We tested the different feature configurations, at \textbf{\gls{acr::efin}} level 3 and in all urban zones.
        Mean precision and recall test results are reported in Table~\ref{tab::ablation_f3}.

        \begin{table}[htpb]
            \footnotesize
            \begin{center}
                \begin{tabular}{| c | c c | c c | c c | c c |}
                    \hline
                    \multicolumn{9}{|c|}{\textbf{Elancourt}}\\
                    \hline
                    &\multicolumn{2}{c|}{\textbf{Geom.}} & \multicolumn{2}{c|}{\textbf{Geom. \(\oplus\) Hei.}} & \multicolumn{2}{c|}{\textbf{Geom. \(\oplus\) Im.}} & \multicolumn{2}{x{2.4cm}|}{\textbf{All}}\\
                    \cline{2-9}
                    & \(\bm{Rec}\) & \(\bm{Prec}\) &  \(\bm{Rec}\) & \(\bm{Prec}\) &  \(\bm{Rec}\) & \(\bm{Prec}\) &  \(\bm{Rec}\) & \(\bm{Prec}\) \\
                    \hline
                    \texttt{BOS} & \textbf{93.96} & \textbf{76.15} & 91.43 & 77.76 & 91.51 & 76.08 & 90.83 & 76.14 \\
                    \hline
                    \texttt{BUS} & 32.98 & 76.47 & \textbf{41.86} & \textbf{75.57} & 40.38 & 71.00 & 39.32 & 71.81 \\
                    \hline
                    \texttt{BIB} & 12.32 & 67.57 & 12.81 & 68.42 & \textbf{16.26} & \textbf{67.35} & 16.75 & 68.0 \\
                    \hline
                    \texttt{BIT} & \textbf{25.25} & \textbf{92.59} & 20.20 & 90.91 & 20.20 & 95.24 & 11.11 & 91.67 \\
                    \specialrule{.2em}{.1em}{.1em}
                    \texttt{FOS} & 98.91 & 99.07 & \textbf{98.91} & \textbf{99.30} & 98.99 & 98.84 & 98.91 & 98.84 \\
                    \hline
                    \texttt{FUS} & \textbf{1.90} & \textbf{54.55} & 0.63 & 66.67 & 1.61 & 50 & 1.27 & 66.67 \\
                    \hline
                    \texttt{FIB} & \textbf{9.17} & \textbf{87.5} & 0 & --- & 8.30 & 82.61 & 7.42 & 100 \\
                    \hline
                    \texttt{FIT} & 6.67 & 100 & \textbf{8.73} & \textbf{95.24} & 3.33 & 100 & 3.33 & 100 \\
                    \hline
                    \texttt{FIG} & \textbf{80.54} & \textbf{73.14} & 80.45 & 72.62 & 78.69 & 72.12 & 79.02 & 71.82 \\
                    \hline
                    \hline
                    \multicolumn{9}{|c|}{\textbf{Nantes}}\\
                    \hline
                    &\multicolumn{2}{c|}{\textbf{Geom.}} & \multicolumn{2}{c|}{\textbf{Geom. \(\oplus\) Hei.}} & \multicolumn{2}{c|}{\textbf{Geom. \(\oplus\) Im.}} & \multicolumn{2}{x{2.4cm}|}{\textbf{All}}\\
                    \cline{2-9}
                    & \(\bm{Rec}\) & \(\bm{Prec}\) &  \(\bm{Rec}\) & \(\bm{Prec}\) &  \(\bm{Rec}\) & \(\bm{Prec}\) &  \(\bm{Rec}\) & \(\bm{Prec}\) \\
                    \hline
                    \texttt{BOS} & \textbf{38.14} & \textbf{61.67} & 36.43 & 60.23 & 36.77 & 62.21 & 34.71 & 60.48 \\
                    \hline
                    \texttt{BUS} & 7.35 & 62.5 & 7.35 & 55.56 & \textbf{29.41} & \textbf{66.67} & 26.47 & 64.29 \\
                    \hline
                    \texttt{BIB} & 0 & --- & 0 & --- & \textbf{1.01} & \textbf{50.0} & \textbf{1.01} & \textbf{50.0} \\
                    \hline
                    \texttt{BIT} & 1.77 & 22.22 & \textbf{3.54} & \textbf{44.44} & 0 & 0 & 2.65 & 50.0 \\
                    \specialrule{.2em}{.1em}{.1em}
                    \texttt{FOS} & \textbf{98.54} & \textbf{98.13} & \textbf{98.54} & \textbf{98.13} & 98.33 & 97.92 & 98.12 & 97.91 \\
                    \hline
                    \texttt{FUS} & 27.62 & 55.24 & \textbf{27.62} & \textbf{59.18} & 24.76 & 54.74 & 23.33 & 53.85 \\
                    \hline
                    \texttt{FIB} & 37.80 & 62.0 & 36.59 & 63.16 & \textbf{49.39} & \textbf{60.90} & 46.39 & 60.90 \\
                    \hline
                    \texttt{FIT} & 0 & --- & 0 & --- & 0 & --- & 0 & --- \\
                    \hline
                    \texttt{FIG} & 86.32 & 78.09 & \textbf{86.77} & \textbf{78.02} & 84.53 & 78.71 & 83.86 & 78.08 \\
                    \hline
                    \hline
                    \multicolumn{9}{|c|}{\textbf{Paris-13}}\\
                    \hline
                    &\multicolumn{2}{c|}{\textbf{Geom.}} & \multicolumn{2}{c|}{\textbf{Geom. \(\oplus\) Hei.}} & \multicolumn{2}{c|}{\textbf{Geom. \(\oplus\) Im.}} & \multicolumn{2}{x{2.4cm}|}{\textbf{All}}\\
                    \cline{2-9}
                    & \(\bm{Rec}\) & \(\bm{Prec}\) &  \(\bm{Rec}\) & \(\bm{Prec}\) &  \(\bm{Rec}\) & \(\bm{Prec}\) &  \(\bm{Rec}\) & \(\bm{Prec}\) \\
                    \hline
                    \texttt{BOS} & 45.54 & 65.25 & 46.53 & 68.61 & \textbf{50.0} & \textbf{68.24} & 46.53 & 70.15 \\
                    \hline
                    \texttt{BUS} & 6.35 & 66.67 & 7.94 & 71.43 & \textbf{22.22} & \textbf{77.78} & 7.94 & 62.5 \\
                    \hline
                    \texttt{BIB} & 0 & --- & 0 & --- & 0 & 0 & 0 & --- \\
                    \hline
                    \texttt{BIT} & \textbf{2.63} & \textbf{50.0} & 0 & --- & 1.32 & 50.0 & 0 & 0 \\
                    \specialrule{.2em}{.1em}{.1em}
                    \texttt{FOS} & 97.19 & 97.19 & 97.19 & 97.19 & \textbf{97.59} & \textbf{98.38} & 97.19 & 97.19 \\
                    \hline
                    \texttt{FUS} & \textbf{85.09} & \textbf{75.0} & 84.36 & 74.12 & 85.09 & 74.52 & 84.36 & 74.12 \\
                    \hline
                    \texttt{FIB} & 53.47 & 62.10 & 51.39 & 61.67 & \textbf{53.47} & \textbf{63.11} & 52.78 & 61.79 \\
                    \hline
                    \texttt{FIT} & 0 & --- & 0 & --- & 0 & --- & 0 & --- \\
                    \hline
                    \texttt{FIG} & 97.65 & 84.62 & \textbf{98.96} & \textbf{84.79} & 97.65 & 84.62 & \textbf{98.96} & \textbf{84.79} \\
                    \hline
                \end{tabular}
            \end{center}
            \caption[
                Baseline feature ablation study results preformed on the three areas at \textbf{\gls{acr::efin}} level 3.
            ]{
                \label{tab::ablation_f3}
                Baseline feature ablation study results preformed on the three areas at \textbf{\gls{acr::efin}} level 3.
                Test results are expressed in percentage.
                All \texttt{atomic} errors are considered over all possible configurations.
                Results in bold indicate the feature configuration with the highest F-score.
            }
        \end{table}

        In Table~\ref{tab::all_f-scores_ablation_f3_viz}, results are classified depending on the F-score using a color scheme.
        We can see how \texttt{FOS} and \texttt{FIG} are always well detected.
        This is mainly due to the fact that they are very frequent in all datasets (cf. Figure~\ref{fig::error_statistics}).
        The same reason explains why \texttt{BOS} is well detected in \textbf{Elancourt}, as well as \texttt{FUS} and \texttt{FIB} are in \textbf{Paris-13}.
        Understandably, rare errors are difficult to detect as shown by \texttt{FIT} on the three zones for instance.

        \begin{table}[htpb]
            \footnotesize
            \centering
            \renewcommand{\arraystretch}{1.5}
            \begin{center}
                \begin{tabular}{| c | x{1.5cm} x{1.5cm} x{1.5cm} x{1.5cm} |}
                    \hline
                    & \multicolumn{4}{c|}{\textbf{Elancourt}}\\
                    \hline
                    &\textbf{Geom.} & \textbf{Geom. \(\oplus\) Hei.} & \textbf{Geom. \(\oplus\) Im.} & \textbf{All}\\
                    \hline
                    \texttt{BOS} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} \\
                    \hline
                    \texttt{BUS} & \cellcolor{LOSS0515} & \cellcolor{LOSS0515} & \cellcolor{LOSS0515} & \cellcolor{LOSS0515} \\
                    \hline
                    \texttt{BIB} & \cellcolor{LOSS2535} & \cellcolor{LOSS2535} & \cellcolor{LOSS2535} & \cellcolor{LOSS2535} \\
                    \hline
                    \texttt{BIT} & \cellcolor{LOSS2535} & \cellcolor{LOSS2535} & \cellcolor{LOSS2535} & \cellcolor{LOSS2535} \\
                    \specialrule{.2em}{.1em}{.1em}
                    \texttt{FOS} & \cellcolor{GAIN45} & \cellcolor{GAIN45} & \cellcolor{GAIN45} & \cellcolor{GAIN45} \\
                    \hline
                    \texttt{FUS} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} \\
                    \hline
                    \texttt{FIB} & \cellcolor{LOSS2535} & \cellcolor{LOSS3545} & \cellcolor{LOSS2535} & \cellcolor{LOSS3545} \\
                    \hline
                    \texttt{FIT} & \cellcolor{LOSS3545} & \cellcolor{LOSS2535} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} \\
                    \hline
                    \texttt{FIG} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} \\
                    \hline
                    \hline
                    & \multicolumn{4}{c|}{\textbf{Nantes}}\\
                    \hline
                    &\textbf{Geom.} & \textbf{Geom. \(\oplus\) Hei.} & \textbf{Geom. \(\oplus\) Im.} & \textbf{All}\\
                    \hline
                    \texttt{BOS} & \cellcolor{LOSS0515} & \cellcolor{LOSS0515} & \cellcolor{LOSS0515} & \cellcolor{LOSS2535} \\
                    \hline
                    \texttt{BUS} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS2535} & \cellcolor{LOSS2535} \\
                    \hline
                    \texttt{BIB} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} \\
                    \hline
                    \texttt{BIT} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} \\
                    \specialrule{.2em}{.1em}{.1em}
                    \texttt{FOS} & \cellcolor{GAIN45} & \cellcolor{GAIN45} & \cellcolor{GAIN45} & \cellcolor{GAIN45} \\
                    \hline
                    \texttt{FUS} & \cellcolor{LOSS2535} & \cellcolor{LOSS2535} & \cellcolor{LOSS2535} & \cellcolor{LOSS2535} \\
                    \hline
                    \texttt{FIB} & \cellcolor{LOSS0515} & \cellcolor{LOSS0515} & \cellcolor{LOSS0515} & \cellcolor{LOSS0515} \\
                    \hline
                    \texttt{FIT} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} \\
                    \hline
                    \texttt{FIG} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} \\
                    \hline
                    \hline
                    & \multicolumn{4}{c|}{\textbf{Paris-13}}\\
                    \hline
                    &\textbf{Geom.} & \textbf{Geom. \(\oplus\) Hei.} & \textbf{Geom. \(\oplus\) Im.} & \textbf{All}\\
                    \hline
                    \texttt{BOS} & \cellcolor{LOSS0515} & \cellcolor{GAIN1525} & \cellcolor{GAIN1525} & \cellcolor{GAIN1525} \\
                    \hline
                    \texttt{BUS} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS2535} & \cellcolor{LOSS3545} \\
                    \hline
                    \texttt{BIB} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} \\
                    \hline
                    \texttt{BIT} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} \\
                    \specialrule{.2em}{.1em}{.1em}
                    \texttt{FOS} & \cellcolor{GAIN45} & \cellcolor{GAIN45} & \cellcolor{GAIN45} & \cellcolor{GAIN45} \\
                    \hline
                    \texttt{FUS} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} & \cellcolor{GAIN2535} \\
                    \hline
                    \texttt{FIB} & \cellcolor{GAIN1525} & \cellcolor{GAIN1525} & \cellcolor{GAIN1525} & \cellcolor{GAIN1525} \\
                    \hline
                    \texttt{FIT} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} & \cellcolor{LOSS3545} \\
                    \hline
                    \texttt{FIG} & \cellcolor{GAIN45} & \cellcolor{GAIN45} & \cellcolor{GAIN45} & \cellcolor{GAIN45} \\
                    \hline
                \end{tabular}
            \end{center}
            \renewcommand{\arraystretch}{1}
            \caption[
                F-scores vizualization for ablation results at \textbf{\gls{acr::efin}} level 3 with baseline features.
            ]{
                \label{tab::all_f-scores_ablation_f3_viz}
                F-scores vizualization for ablation results at \textbf{\gls{acr::efin}} level 3 with baseline features.
                These are deduced from Table~\ref{tab::all_f-scores_ablation_f3}.
                The color indicates the how well detected a label is: 
                \textcolor{LOSS3545}{\(\blacksquare\)}: [\SIrange[range-phrase={, }]{0}{15}{\percent})--
                \textcolor{LOSS2535}{\(\blacksquare\)}: [\SIrange[range-phrase={, }]{15}{45}{\percent}) --
                \textcolor{LOSS0515}{\(\blacksquare\)}: [\SIrange[range-phrase={, }]{45}{55}{\percent}) --
                \textcolor{GAIN1525}{\(\blacksquare\)}: [\SIrange[range-phrase={, }]{55}{70}{\percent})--
                \textcolor{GAIN2535}{\(\blacksquare\)}: [\SIrange[range-phrase={, }]{70}{85}{\percent})--
                \textcolor{GAIN45}{\(\blacksquare\)}: [\SIrange[range-phrase={, }]{85}{100}{\percent}].
            }
        \end{table}

        \begin{figure}[htpb]
            \centering
            \ffigbox[\FBwidth]{
                \begin{subfloatrow}[2]
                    \ffigbox[\FBwidth]{
                        \includestandalone[mode=buildnew, height=7.5cm]{figures/results/ablation/building}
                    }{
                        \caption{
                            \label{subfig::f_score_ablation_f3_building}
                            \texttt{Building errors.}
                        }
                    }
                    \ffigbox[\FBwidth]{
                        \includestandalone[mode=buildnew, height=7.5cm]{figures/results/ablation/facet}
                    }{
                        \caption{
                            \label{subfig::f_score_ablation_f3_facet}
                            \texttt{Facet errors.}
                        }
                    }
                \end{subfloatrow}
            }{
                \caption[
                    Visualizing mean F-score and standard deviation for the feature ablation study.
                ]{
                    \label{fig::f_score_ablation_f3}
                    Visualizing mean F-score and standard deviation for the feature ablation study.
                    Details are reported in Table~\ref{tab::f_score_ablation_f3}.
                }
            }
        \end{figure}

        F-scores are averaged across all feature configurations and represented in Figure~\ref{fig::f_score_ablation_f3}.
        The first thing we can observe is the fact that geometric features alone give comparable results to ones where extrinsic modalities are added.
        This was the case for most errors as confirmed by the low variance in F-score.
        However, in some exceptional cases, adding more modalities impacts greatly the results as shown in Table~\ref{tab::all_f-scores_ablation_f3}.
        The first case regards \texttt{BUS}.
        In fact, on \textbf{Elancourt}, height and image based features both contribute to an increase of around \SI{6}{\percent} in F-score.
        This can be explained by the fact that a lot of under-segmented building models have different heights which reflects easily on height based features.
        Similar behaviour occurs for \textbf{Nantes} and \textbf{Paris-13} with image based features driving at least a \SI{20}{\percent} jump in F-score.
        In fact, buildings could be identified by their roof texture or color, as depicted in Figure~\ref{subfig::bus_2d}.
        As a consequence, image based features are instrumental in detecting the discrepancy between two under-segmented buildings, especially in dense uniform settings.
        The second and less important example is \texttt{FIB} on \textbf{Nantes} where image based features adds around \SI{10}{\percent} in F-score as designed in Section~\ref{subsec::learned_evaluation::baseline::image}.
        Last comes the case of \texttt{BIT}, on \textbf{Elancourt}, which performs at least \SI{6}{\percent} worse when adding more modalities.

        This can be actually interpreted by the fact that geometric features, take into account intrinsic attributes of a building model.
        These features could, in turn, be intuitively related to the type of building they describe.
        Consequently, the big role that this kind of features plays in detecting errors implies that the existence of a defect is highly correlated to the type of model it affects.\\
        This is, in fact, expected for errors of topological nature as the geometric structure of the model is assessed.
        As an example, we can see how \texttt{BOS} is better detected on \textbf{Elancourt} and \textbf{Nantes} based on geometric features only.
        Extrinsic features, on the other hand, act more as clues in predicting these types of errors as discussed with \texttt{BUS} in the previous paragraph.\\

        Conversely, the image and height based features are expected to yield at least as good results as the intrinsic features alone for fidelity defects.
        In fact, in Table~\ref{tab::ablation_f3}, \texttt{BIB} as well as \texttt{FIB} and \texttt{FIG} are better detected, in terms of F-score, when adding height or image based modalities.
        The exception is \texttt{FIB} and \texttt{FIG} on \textbf{Elancourt} where only geometric features yielded better results.
        This may be explained by the fact that the baseline features are not rich enough and the shear number of training instances in \textbf{Elancourt} was sufficient to link building model types to the occurence of such errors.\\

        Figure~\ref{fig::f_score_ablation_f3} shows that all \texttt{Building errors} labels are better detected on \textbf{Elancourt}.
        Moreover, we can even establish that the more the urban scene is dense the more difficult \gls{acr::lod}-0 \(\cup\) \gls{acr::lod}-1 errors detection becomes.
        There is one exception where \texttt{BOS} existence is slightly better predicted on \textbf{Paris-13} than on \textbf{Nantes}.
        This may be attributed to the low number of training samples on both these zones, as they are not sufficiently representative of the actual scenes.
        On the other hand, \texttt{Facet errors} F-scores are proportional to the density of the studied urban scene, minding two exceptions.
        \texttt{FOS} and \texttt{FIT} F-scores are actually stable across the different urban areas suffering only from slight decreases that can be attributed to noise.
        This can be due to the fact that \texttt{FOS} is highly frequent in all urban scenes and so easily predictable that F-scores cannot get any better. 
        Conversely, \texttt{FIT} are so rare (cf. Figure~\ref{subfig::lod2_errors}) their existance is barely predictable.

    \subsection{Feature importance}
        \label{subsec::experiments::baseline_feature_analysis::feature_importance}
        \begin{figure}[htpb]
            \centering
            \ffigbox[\FBwidth]{
                \begin{subfloatrow}
                    \ffigbox[\FBwidth]{
                        \includestandalone[mode=buildnew, height=.23\textheight]{figures/results/ablation/feature_importance/building}
                    }{
                        \caption{
                            \label{subfig::feature_importances_rf_bl_building}
                            \texttt{Building errors.}
                        }
                    }
                    \ffigbox[\FBwidth]{
                        \includestandalone[mode=buildnew, height=.23\textheight]{figures/results/ablation/feature_importance/facet}
                    }{
                        \caption{
                            \label{subfig::feature_importances_rf_bl_facet}
                            \texttt{Facet errors.}
                        }
                    }
                \end{subfloatrow}
            }{
                \caption[
                    Modality importance computed by stacking single feature importances retrieved from the \gls{acr::rf} classifier.
                ]{
                    \label{fig::feature_importances_rf_bl}
                    Modality importance computed by stacking single feature importances retrieved from the \gls{acr::rf} classifier.
                    The first (\textit{resp.} second and third) column represents \textbf{Elancourt} (\textit{resp.} \textbf{Nantes} and \textbf{Paris-13}).
                }
            }
        \end{figure}
        
        \gls{acr::rf} classifiers can easily infer feature importances at training time.
        These were here computed and aggregated by modality in all urban scenes (cf. Figure~\ref{fig::feature_importances_rf_bl}).\\

        At first, we observe how much individual attributes are important before being gathered.
        For geometric features, all attributes are equally important.
        However, concerning image and height based features, only a few are relevant (i.e., they have a higher feature importance ratio).
        Indeed, these few attributes correspond to the highest and lowest values of the histograms.
        As described earlier, image and height features consist of a histogram of distances between the model and the real measured signals:
        vector cosine similarity, for the first, and the \(L_2\) norm for the last.
        It is clear that the presence of errors would result in saturating the high values in the histogram, while an absence of defects would imply a big number of low values.
        This is one intuitive explaination of this observed phenomenon.\\
        
        In a second time, we notice that no modality is more important than the others, contrarily to what was observed in Table~\ref{tab::ablation_f3}.
        In fact, as shown in Section~\ref{subsec::experiments::baseline_feature_analysis::ablation}, for most \texttt{atomic} errors, test results using geometric features are comparable to those obtained with more modalities.
        However, during training, all modalities are relevant with importance ratios approximating \num[fraction-function = \sfrac]{1/3} as shown in Figure~\ref{fig::feature_importances_rf_bl}.
        As a consequence, for subsequent experimentations all configurations are taken into consideration.

    \subsection{Summary}
        \label{subsec::experiments::baseline_feature_analysis::summary}
        In this section, we have used the \gls{acr::rf} classifier on two types of features: a simple \gls{acr::rmse} and the custom build baseline features.
        From the experimental results, we have learned that:
        \begin{itemize}[label=\(\blacktriangleright\)]
            \item The \gls{acr::rmse} fails completly to predict errors defined in our taxonomy;
            \item \texttt{Building errors} are better detected on \textbf{Elancourt} than on the other scenes;
            \item \texttt{FOS} is very well detected with over \SI{95}{\percent} in F-score, over all areas of interest;
            \item Except \texttt{FOS}, the more the urban zone is dense the better \texttt{Facet erros} are detected;
            \item Rare errors such as \texttt{BIT} and \texttt{FIT} (on all urban areas) are poorly detected;
            \item Geometric features alone is, with a small margin, as good as the other extrinsic based configurations for error detection;
            \item Consequently, the building type is a good indicator for error detection in the same area;
            \item \texttt{BUS} is the only error that the other modalities are better at with a large gap;
            \item Although, in most cases, not improving error prediction, external data based modalities are as important as geometric features.
        \end{itemize}
