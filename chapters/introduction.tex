\chapter{Introduction}
    \minitoc
    \section{Context and objectives}
        3D urban models have a wide range of applications. They can be used for consumer purposes (video games or tourism) as much as they can be vital in more critical domains with significant societal challenges (\textit{e.g.}, disaster control, run-off water or microclimate simulation, urban planning or security operations preparation)~\citep{Musialski2012,Biljecki2015}. Therefore, automatic urban reconstruction from geospatial imagery (spatial/airborne sensors) focuses efforts on both scientific research and industrial activities. 3D city modeling has therefore been deeply explored in the photogrammetric, GIS, computer vision, and computer graphics literature with an emphasis on compactness, full automation, robustness to acquisition constraints, scalability, and inevitably, quality \citep{Muller,OVER2010496,Vanegas,lafarge2012creating,Poli2013,stoter,ZHOU2013118,Cabezas,Monszpart,Kelly,nguatem2017modeling}. However, the problem remains partly unsolved~\citep{SESTER2011155, Musialski2012, rottensteiner2014results}. In fact, besides the seamless nature of reconstituted models, current algorithms lack of generalization capacity. They cannot handle the high heterogeneity of urban landscapes. As such, for operational purposes, human intervention is needed either in interaction within the reconstruction pipeline or as a post-processing refinement and correction step. The latter is highly tedious: it consists in an individual visual inspection of buildings~\citep{Musialski2012}. Consequently, automatizing the last step remains, for all stakeholders (from researchers up to end-users), a critical step, especially in a production environment. It has been barely investigated in the literature. This paper addresses this issue by expanding earlier work in~\citep{Ennafii2019}.

        % \begin{figure}
        %     \begin{center}
        %         % \includestandalone[mode=buildnew, width=\textwidth]{graphical_abstract}
        %         \caption{\label{fig::pipeline} Our semantic evaluation paradigm proposal for 3D building models (a). Semantic errors affecting the building are predicted using a supervised classifier and handcrafted features. In addition to the input model topological structure (b), features are extracted from Very High resolution overhead data. It can be based on a comparison with the \gls*{acr::dsm} (c). Optical images can also be used through for instance local gradient extraction (d). Several errors can be detected at the same time, in a hierarchical manner (e).}
        %     \end{center}
        % \end{figure}

    \section{Qualifying 3D building models}
        % Our work focuses on assessing polyhedral structured 3D models, representing building architectures. These models result from a given urban reconstruction method, that is unknown from our evaluation pipeline. We discard triangle meshes that are standardly generated from multiview images or point clouds with state-of-the-art surface reconstruction methods. Here, the studied objects are, by design, more compact but less faithful to input data. In counterpart, they hold more semantic information: each polygonal facet typically corresponds to a fa\c{c}ade, a roof, or any other architecturally atomic feature of a building. 3D modeling algorithms traditionally build a compromise between representation compactness and fidelity to the input data (meshes or 3D points). Depending on its spatial accuracy, the urban setting, and the targeted application, the reconstituted result achieves a certain \textbf{\gls*{acr::lod}}~\citep{kolbe2005citygml}. A \gls*{acr::lod}-1 model is a simple building extrusion (flat roof)~\citep{biljecki2017generating, ledoux2011topologically}. A \gls*{acr::lod}-2 model considers geometric simplification of buildings, ignoring superstructures, such as dormer windows and chimneys~\citep{Taillandier2004}. These are taken into account in \gls*{acr::lod}-3~\citep{Bredif2007}. The \gls*{acr::lod} rational is still open for debate~\citep{2016_ceus_improved_lod}. Nevertheless, in this paper, we will follow the \gls*{acr::lod} categorization introduced above, which is also standard in the computer vision and graphics literature.

        A large body of papers has addressed the 3D building modeling issue and subsequently tried to find the trade-off between fidelity and compactness~\citep{dick2004modelling, zebedin2008fusion, Lafarge2010, verdie2015lod}. Conversely, few works investigate the issue of assessing the quality of the derived models, especially out of a given reconstruction pipeline. Usually, quality assessment is based on visual inspection~\citep{Durupt2006, MacayMoreia2013} or geometric fidelity metrics~\citep{Kaartinen2005} without any localized semantic dimension. Only one benchmark dataset has addressed the issue~\citep{rottensteiner2014results}. It remains focused on very few areas and a geometric comparison with manually extracted roof structures~\citep{li2016boxfitting, nan2017polyfit, nguatem2017modeling}. Consequently, it cannot be easily extended.

    \section{Positioning and contributions}
        % The current situation motivates the need for a well suited quality assessment paradigm. Since the building models display strong structural properties, an unconstrained evaluation based on data fidelity metrics, as in~\citep{berger2013benchmark}, is too general. The evaluation should also ignore format issues or geometric consistencies as proposed in~\citep{ledoux2018val3dity}. We consider they have been ruled out before this stage. Instead, we target a \textit{semantic} evaluation in which building semantics is taken into account through the detection and categorization of modeling errors at the facet level for each 3D building. The framework is independent from the \gls*{acr::lod} and the modeling method. The standard criteria used in the reconstruction process (\textit{e.g.}, $L_1$ norm between the model and a \gls*{acr::dsm}) will not be taken into account, as they are usually chosen as minimization targets in the modeling procedure . Thus, we define an evaluation framework that can be used for:
        \begin{itemize}
            \item \textbf{Building model correction}: for the automatic or interactive~\citep{kowdle2011active} refinement of building models using the detected errors.
            \item \textbf{Change detection}: modeling errors can straightforwardly stem from changes, which frequently occur in urban environments~\citep{taneja2015geometric}. Conversely, changes can be implicitly detected from other defects.
            % \item \textbf{Reconstruction method selection}: evaluating models from various reconstruction algorithms can allow assessing which method(s) is(are) the most adapted for a specific \gls*{acr::lod} and building type.
            \item \textbf{Crowd-sourcing evaluation}~\citep{kovashka2016crowdsourcing}: by categorizing user behaviors during crowd-sourced modeling and vandalism detection process~\citep{neis2012towards}.
        \end{itemize}
        
        This work proposes an adaptable and flexible framework indifferent to input urban scenes and reconstruction methods (Figure~\ref{fig::pipeline}). For that purpose, our contributions are three-fold:
        \begin{itemize}
            % \item A new \textbf{taxonomy of errors}, hierarchical, adapted to all \gls*{acr::lod}s, and independent from input models;
            \item A \textbf{supervised classification} formulation of the evaluation problem which predicts all errors affecting the building model;
            \item A multimodal \textbf{baseline of features} that are extracted from the model itself as well as from Very High Resolution external data (optical images and height data).
        \end{itemize}
    
    \section{Structure of the Thesis}
        Section~\ref{sec::related} introduces the problem of the evaluation of 3D building models and discusses existing methods. Section~\ref{sec::approach} details the proposed approach, while data and experiments conducted over three urban areas are presented in Section~\ref{sec::expe}. A more detailed ap. Main conclusions are drawn in Section~\ref{sec::conclusion}.

